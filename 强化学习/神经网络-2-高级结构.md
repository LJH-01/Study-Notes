# 神经网络-2 高级神经网络结构

## 1.卷积神经网络 CNN

[链接----详解卷积神经网络](https://blog.csdn.net/qq_25762497/article/details/51052861)

1. 卷积神经网络CNN 最常应用的方面是计算机图片识别。

> * 卷积层（Convolutional layer），卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。
> * 线性整流层（Rectified Linear Units layer, ReLU layer），这一层神经的活性化函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）f(x)=max(0,x)f(x)=max(0,x)。
> * 池化层（Pooling layer），通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。
> * 全连接层（ Fully-Connected layer）, 把所有局部特征结合变成全局特征，用来计算最后每一类的得分

2. 搭建一个CNN

	* 一个卷积神经网络一般包括：

		``` python 
		class CNN(nn.Module):
		    def __init__(self):
		        super(CNN, self).__init__()
		        self.conv1 = nn.Sequential( # input shape (1, 28, 28)
		            nn.Conv2d(				# 一个Conv2d是一个过滤器
		                in_channels=1,      # input height
		                out_channels=16,    # n_filters
		                kernel_size=5,      # filter size
		                stride=1,           # filter movement/step
		                padding=2,      	# 如果想要 con2d 出来的图片长宽没有变化, padding=
		            ),    					# (kernel_size-1)/2 当 stride=1
		                    				# output shape (16, 28, 28)
		            nn.ReLU(),    			# activation
		            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, 
		        )    								# output shape (16, 14, 14)
		        self.conv2 = nn.Sequential(  		# input shape (16, 14, 14)
		            nn.Conv2d(16, 32, 5, 1, 2),  	# output shape (32, 14, 14)
		            nn.ReLU(),  					# activation
		            nn.MaxPool2d(2),  				# output shape (32, 7, 7)
		        )
		        self.out = nn.Linear(32 * 7 * 7, 10)   	# fully connected layer,
		        										# output 10 classes
		
		    def forward(self, x):
		        x = self.conv1(x)
		        x = self.conv2(x)
		        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)
		        output = self.out(x)
		        return output
		
		```

	* Optimizer 和  LossEntropy 是训练的时候才用的到

	* ```pyton
		loss = loss_func(output, b_y)   # cross entropy loss
		        optimizer.zero_grad()           # clear gradients for this training step
		        loss.backward()                 # backpropagation, compute gradients
		        optimizer.step()                # apply gradients
		```

## 2.循环神经网络RNN

1. 简介：

	> * RNN神经网络具备记住之前发生的事的能力，在分析 Data0 的时候, 我们把分析结果存入记忆. 然后当分析 data1的时候, NN会产生新的记忆, 我们就简单的把老记忆调用过来, 一起分析. 如果继续分析更多的有序数据 , RNN就会把之前的记忆都累积起来, 一起分析。
	> * 数学描述： 每次 RNN 运算完之后都会产生一个对于当前状态的描述 , state. 用S( t) 代替, 然后RNN开始分析 x(t+1) , 根据 x(t+1)产生s(t+1), 不过此时 y(t+1) 是由 s(t) 和 s(t+1) 共同创造的。
	> * 循环网络RNN最常用在语言识别。RNN的结构比较自由。

2. LSTM-RNN 当下最流行的的RNN之一

	> * 因为有梯度消失和梯度爆炸问题，所以RNN通常无法会议久远的记忆，
	> * 梯度消失和梯度爆炸：在误差反向传递的时候，会乘上一个参数，如果大于1，累乘后梯度爆炸；如果小于1，累乘后梯度消失。
	> * LSTM 就是为了解决这个问题而诞生的. LSTM 和普通 RNN 相比, 多出了三个控制器. (输入控制, 输出控制, 忘记控制

3. 搭建RNN循环神经网络

```python 
# 用LSTM-RNN做的分类手写数据
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.LSTM(     # LSTM 效果要比 nn.RNN() 好多了
            input_size=28,      # 图片每行的数据像素点
            hidden_size=64,     # rnn hidden unit 神经元个数
            num_layers=1,       # 有几层 RNN layers
            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)
        )

        self.out = nn.Linear(64, 10)    # 输出层

    def forward(self, x):
        # x shape (batch, time_step, input_size)
        # r_out shape (batch, time_step, output_size)
        # h_n shape (n_layers, batch, hidden_size)   LSTM 有两个 hidden states, h_n 是分线, h_c 是主线
        # h_c shape (n_layers, batch, hidden_size)
        r_out, (h_n, h_c) = self.rnn(x, None)   # None 表示 hidden state 会用全0的 state

        # 选取最后一个时间点的 r_out 输出
        # 这里 r_out[:, -1, :] 的值也是 h_n 的值
        out = self.out(r_out[:, -1, :])
        return out
```

```python 
RNN--回归
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.RNN(  # 这回一个普通的 RNN 就能胜任
            input_size=1,
            hidden_size=32,     # rnn hidden unit
            num_layers=1,       # 有几层 RNN layers
            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h_state):  # 因为 hidden state 是连续的, 所以我们要一直传递这一个 state
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, output_size)
        r_out, h_state = self.rnn(x, h_state)   # h_state 也要作为 RNN 的一个输入

        outs = []    # 保存所有时间点的预测值
        for time_step in range(r_out.size(1)):    # 对每一个时间点计算 output
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state
```

## 3.自编码器

1. 简介

> 1. 自编码是一种神经网络形式。
> 2. 作用：提取出原图片中的最具代表性的信息, 缩减输入信息量, 再把缩减过后的信息放进神经网络学习。
> 3. 原理：通过将原数据白色的X 压缩, 解压 成黑色的X, 然后通过对比黑白 X ,求出预测误差, 进行反向传递, 逐步提升自编码的准确性. 训练好的自编码中间这一部分就是能总结原数据的精髓.。
> 4. 从头到尾, 我们只用到了输入数据 X, 并没有用到 X 对应的数据标签, 所以也可以说自编码是一种非监督学习. 到了真正使用自编码的时候. 通常只会用到自编码前半部分.

2. 搭建一个AutoEncoder

```python 
class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()

        # 压缩
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 128),
            nn.Tanh(),
            nn.Linear(128, 64),
            nn.Tanh(),
            nn.Linear(64, 12),
            nn.Tanh(),
            nn.Linear(12, 3),   # 压缩成3个特征, 进行 3D 图像可视化
        )
        # 解压
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.Tanh(),
            nn.Linear(12, 64),
            nn.Tanh(),
            nn.Linear(64, 128),
            nn.Tanh(),
            nn.Linear(128, 28*28),
            nn.Sigmoid(),       # 激励函数让输出值在 (0, 1)
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded
```

3.总结

>AutoEncoder和Auto Decoder搭配使用可以同decoder的误差反向传播来优化Encoder提取关键信息的能力，当encoder训练的足够好了，可以用来提取图片中的关键信息，来加快另一个神经网络的训练。

## 4.DQN

## 5.生成对抗网络（GAN）

> 与其他的不同：神经网络分很多种, 有普通的前向传播神经网络 , 有分析图片的 CNN 卷积神经网络 , 有分析序列化数据的 RNN 循环神经网络 , 这些神经网络都是用来输入数据, 得到想要的结果, 我们看中的是这些神经网络能很好的将数据与结果通过某种关系联系起来.

1. GAN是生成网络的一种，不是为了将数据和结果关联而是为了生成数据，例如让机器创造音乐，写文章等。

>Generator 会根据随机数来生成有意义的数据 , Discriminator 会学习如何判断哪些是真实数据 , 哪些是生成数据, 然后将学习的经验反向传递给 Generator, 让 Generator 能根据随机数生成更像真实数据的数据

2. 搭建一个GAN

```python 
G = nn.Sequential(                      # Generator
    nn.Linear(N_IDEAS, 128),            # random ideas (could from normal distribution)
    nn.ReLU(),
    nn.Linear(128, ART_COMPONENTS),     # making a painting from these random ideas
)

D = nn.Sequential(                      # Discriminator
    nn.Linear(ART_COMPONENTS, 128),     # receive art work either from the famous artist or a newbie like G
    nn.ReLU(),
    nn.Linear(128, 1),
    nn.Sigmoid(),                       # tell the probability that the art work is made by artist
)
```

```py
for step in range(10000):
    artist_paintings = artist_works()           # real painting from artist
    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS)    # random ideas
    G_paintings = G(G_ideas())                  # fake painting from G (random ideas)

    prob_artist0 = D(artist_paintings)          # D try to increase this prob
    prob_artist1 = D(G_paintings)               # D try to reduce this prob
```

```py
 D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1. - prob_artist1))
 G_loss = torch.mean(torch.log(1. - prob_artist1))
```

```py
    opt_D.zero_grad()
    D_loss.backward(retain_graph=True)      # retain_graph 这个参数是为了再次使用计算图纸
    opt_D.step()

    opt_G.zero_grad()
    G_loss.backward()
    opt_G.step()
```

-------

### 6.其他

1. pytorch 是动态的
2. 使用GPU加速运算：加 .cuda() 变GPU可以运算的模式。加.cpu() 变CPU可运算模式

> 在 GPU 训练可以大幅提升运算速度. Torch 有一套很好的 GPU 运算体系.但是：
>
> * 你的电脑里有合适的 GPU 显卡(NVIDIA), 且支持 CUDA 模块.
>
> * 必须安装 GPU 版的 Torch.
> 	将每次的要计算的 data 变成 GPU 形式. + `.cuda()`
>
> 如果还有些计算是需要在 CPU 上进行的话, 比如 `plt` 的可视化, 我们需要将这些计算或者数据转移至 CPU.
>
> `cpu_data = gpu_data.cpu()`

1. 过拟合的解决：
  1. 增加数据量, 大部分过拟合产生的原因是因为数据量太少了.
  2. 运用正规化.：L1,L2,L3,L4......适用于大多数神经网络和机器学习
  3.  dropout：专门适用于神经网络
2. dropout方法：训练时误差已经降得足够低, 测试的时候误差突然飙升. 很有可能就是出现了过拟合现象。使用

```python
net_overfitting = torch.nn.Sequential(
    torch.nn.Linear(1, N_HIDDEN),
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, N_HIDDEN),
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, 1),
)

net_dropped = torch.nn.Sequential(
    torch.nn.Linear(1, N_HIDDEN),
    torch.nn.Dropout(0.5),  # drop 50% of the neuron
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, N_HIDDEN),
    torch.nn.Dropout(0.5),  # drop 50% of the neuron
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, 1),
)
```

5. batch normalization 批标准化

>  批标准化和普通的数据标准化类似, 是将分散的数据统一的一种做法, 也是优化神经网络的一种方法. 具有统一规格的数据, 能让机器学习更容易学习到数据之中的规律.-----15/16年提出的技术

不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生.到了隐藏层当中, 不能对隐藏层的输入结果进行像之前那样的normalization 处理, batch normalization, 正是处理这种情况.

使用方法：

```python 
nn.BatchNorm1d(1, momentum=0.5)#1是输入值，momentum=0.5而是用来平滑化 batch mean and stddev 的
```

