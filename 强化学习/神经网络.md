# 神经网络

有分析图片的 CNN 卷积神经网络 , 有分析序列化数据, 比如语音的 RNN 循环神经网络

误差反向传递

人工神经网络：本质上是一个能让计算机处理和优化的数学模型

-----卷积神经网络，卷积是一种运算，卷积神经网络最常被应用的方面是计算机的图像识别, 不过因为不断地创新, 它也被应用在视频分析, 自然语言处理, 药物发现, 等等.

-----循环神经网络处理序列数据的神经网络，

-----LSTM,普通 RNN 没有办法回忆起久远记忆，因为误差参数大于1或者小于1 会出现提督爆炸或者梯度消失，LSTM 就是为了解决这个问题而诞生的，可以回忆起久远记忆.

-----自编码，Autoencoder 是一种神经网络的形式，也可以说自编码是一种非监督学习。encoder 编码器. 编码器能得到原数据的精髓。解码器 Decoder。 作用就是从源数据中（可能数据量很大，数据很复杂）提取关键信息，进行学习，然后在解码还原，通常应用中只使用前半部分

-----生成式对抗网络（GAN, Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。

神经网络：输入，提取特征，……输出

+++++梯度下降：

-----迁移学习 transfer learning 迁移学习可以将已习得的强大技能迁移到相关的的问题上。
---

神经网络技巧：

----检验神经网络：通常会把收集到的数据分为训练数据 和 测试数据, 一般用于训练的数据可以是所有数据的70%, 剩下的30%可以拿来测试学习结果. 评价有几个标准：误差曲线、准确度曲线、正规化（解决过拟合问题）、交叉验证

----特征标准化：可以快速推进机器学习的学习速度, 还可以避免机器学习 学得特扭曲.

----选择好特征： 避免无意义的信息, 避免重复性的信息, 避免复杂的信息. 

----激励函数：在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐的激励函数是 relu. 在循环神经网络中 recurrent neural networks, 推荐的是 tanh 或者是 relu 

----过拟合 overfitting 。解决方法： 一、增加数据量。二、运用正规化.  还有一种专门用在神经网络的正规化的方法, 叫作 dropout

----加快训练过程：SGD，Momentum 更新方法、AdaGrad更新方法、RMSProp更新方法、Adam更新方法、

----处理不均衡数据：解决办法：获取更多数据，更换评判方式、重组数据、使用其他机器学习方法、修改算法

----批标准化 

----L1/L2正规化

---

卷积神经网络通常包含以下几种层：

* 卷积层（Convolutional layer），卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。
* 线性整流层（Rectified Linear Units layer, ReLU layer），这一层神经的活性化函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）f(x)=max(0,x)。
* 池化层（Pooling layer），通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。
* 全连接层（ Fully-Connected layer）, 把所有局部特征结合变成全局特征，用来计算最后每一类的得分。
