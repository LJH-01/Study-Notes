# 神经网络-2 高级神经网络结构

## 1.卷积神经网络 CNN

[链接----详解卷积神经网络](https://blog.csdn.net/qq_25762497/article/details/51052861)

1. 卷积神经网络CNN 最常应用的方面是计算机图片识别。

> * 卷积层（Convolutional layer），卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。
> * 线性整流层（Rectified Linear Units layer, ReLU layer），这一层神经的活性化函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）f(x)=max(0,x)f(x)=max(0,x)。
> * 池化层（Pooling layer），通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。
> * 全连接层（ Fully-Connected layer）, 把所有局部特征结合变成全局特征，用来计算最后每一类的得分

2. 搭建一个CNN

	* 一个卷积神经网络一般包括：

		``` python 
		class CNN(nn.Module):
		    def __init__(self):
		        super(CNN, self).__init__()
		        self.conv1 = nn.Sequential( # input shape (1, 28, 28)
		            nn.Conv2d(				# 一个Conv2d是一个过滤器
		                in_channels=1,      # input height
		                out_channels=16,    # n_filters
		                kernel_size=5,      # filter size
		                stride=1,           # filter movement/step
		                padding=2,      	# 如果想要 con2d 出来的图片长宽没有变化, padding=
		            ),    					# (kernel_size-1)/2 当 stride=1
		                    				# output shape (16, 28, 28)
		            nn.ReLU(),    			# activation
		            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, 
		        )    								# output shape (16, 14, 14)
		        self.conv2 = nn.Sequential(  		# input shape (16, 14, 14)
		            nn.Conv2d(16, 32, 5, 1, 2),  	# output shape (32, 14, 14)
		            nn.ReLU(),  					# activation
		            nn.MaxPool2d(2),  				# output shape (32, 7, 7)
		        )
		        self.out = nn.Linear(32 * 7 * 7, 10)   	# fully connected layer,
		        										# output 10 classes
		
		    def forward(self, x):
		        x = self.conv1(x)
		        x = self.conv2(x)
		        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)
		        output = self.out(x)
		        return output
		
		```

	* Optimizer 和  LossEntropy 是训练的时候才用的到

	* ```pyton
		loss = loss_func(output, b_y)   # cross entropy loss
		        optimizer.zero_grad()           # clear gradients for this training step
		        loss.backward()                 # backpropagation, compute gradients
		        optimizer.step()                # apply gradients
		```

## 2.递归/循环神经网络RNN--两个是有区别的

1. 简介：

	> * RNN神经网络具备记住之前发生的事的能力，在分析 Data0 的时候, 我们把分析结果存入记忆. 然后当分析 data1的时候, NN会产生新的记忆, 我们就简单的把老记忆调用过来, 一起分析. 如果继续分析更多的有序数据 , RNN就会把之前的记忆都累积起来, 一起分析。
	> * 数学描述： 每次 RNN 运算完之后都会产生一个对于当前状态的描述 , state. 用S( t) 代替, 然后RNN开始分析 x(t+1) , 根据 x(t+1)产生s(t+1), 不过此时 y(t+1) 是由 s(t) 和 s(t+1) 共同创造的。
	> * 递归神经网络RNN最常用在语言识别。RNN的结构比较自由。

2. LSTM-RNN 当下最流行的的RNN之一

	> * 因为有梯度消失和梯度爆炸问题，所以RNN通常无法会议久远的记忆，
	> * 梯度消失和梯度爆炸：在误差反向传递的时候，会乘上一个参数，如果大于1，累乘后梯度爆炸；如果小于1，累乘后梯度消失。
	> * LSTM 就是为了解决这个问题而诞生的. LSTM 和普通 RNN 相比, 多出了三个控制器. (输入控制, 输出控制, 忘记控制

3. 搭建RNN循环神经网络

```python 
# 用LSTM-RNN做的分类手写数据
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.LSTM(     # LSTM 效果要比 nn.RNN() 好多了
            input_size=28,      # 图片每行的数据像素点
            hidden_size=64,     # rnn hidden unit 神经元个数
            num_layers=1,       # 有几层 RNN layers
            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)
        )

        self.out = nn.Linear(64, 10)    # 输出层

    def forward(self, x):
        # x shape (batch, time_step, input_size)
        # r_out shape (batch, time_step, output_size)
        # h_n shape (n_layers, batch, hidden_size)   LSTM 有两个 hidden states, h_n 是分线, h_c 是主线
        # h_c shape (n_layers, batch, hidden_size)
        r_out, (h_n, h_c) = self.rnn(x, None)   # None 表示 hidden state 会用全0的 state

        # 选取最后一个时间点的 r_out 输出
        # 这里 r_out[:, -1, :] 的值也是 h_n 的值
        out = self.out(r_out[:, -1, :])
        return out
```

```python 
RNN--回归
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.RNN(  # 这回一个普通的 RNN 就能胜任
            input_size=1,
            hidden_size=32,     # rnn hidden unit
            num_layers=1,       # 有几层 RNN layers
            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h_state):  # 因为 hidden state 是连续的, 所以我们要一直传递这一个 state
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, output_size)
        r_out, h_state = self.rnn(x, h_state)   # h_state 也要作为 RNN 的一个输入

        outs = []    # 保存所有时间点的预测值
        for time_step in range(r_out.size(1)):    # 对每一个时间点计算 output
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state
```

## 3.自编码器

1. 简介

> 1. 自编码是一种神经网络形式。
> 2. 作用：提取出原图片中的最具代表性的信息, 缩减输入信息量, 再把缩减过后的信息放进神经网络学习。
> 3. 原理：通过将原数据白色的X 压缩, 解压 成黑色的X, 然后通过对比黑白 X ,求出预测误差, 进行反向传递, 逐步提升自编码的准确性. 训练好的自编码中间这一部分就是能总结原数据的精髓.。
> 4. 从头到尾, 我们只用到了输入数据 X, 并没有用到 X 对应的数据标签, 所以也可以说自编码是一种非监督学习. 到了真正使用自编码的时候. 通常只会用到自编码前半部分.

2. 搭建一个AutoEncoder

```python 
class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()

        # 压缩
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 128),
            nn.Tanh(),
            nn.Linear(128, 64),
            nn.Tanh(),
            nn.Linear(64, 12),
            nn.Tanh(),
            nn.Linear(12, 3),   # 压缩成3个特征, 进行 3D 图像可视化
        )
        # 解压
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.Tanh(),
            nn.Linear(12, 64),
            nn.Tanh(),
            nn.Linear(64, 128),
            nn.Tanh(),
            nn.Linear(128, 28*28),
            nn.Sigmoid(),       # 激励函数让输出值在 (0, 1)
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded
```

3.总结

>AutoEncoder和Auto Decoder搭配使用可以同decoder的误差反向传播来优化Encoder提取关键信息的能力，当encoder训练的足够好了，可以用来提取图片中的关键信息，来加快另一个神经网络的训练。

## 4.DQN

1. 强化学习

* **智能体Agent** 和**环境Environment** 之间的交互。
* Observation 观察------动作Action-------反馈值Reward。
* 动作集合的数量将直接影响整个任务的求解难度，因此DeepMind才从玩最简单的游戏做起，DQN算法（不考虑其变种）仅适用于离散输出问题。
* 状态与动作的关系其实就是输入与输出的关系，而状态State到动作Action的过程就称之为一个**策略Policy**
* 增强学习的任务就是找到一个最优的策略Policy从而使Reward最多。
* 我们一开始并不知道最优的策略是什么，因此往往从随机的策略开始，使用随机的策略进行试验，就可以得到一系列的状态,动作和反馈我们一开始并不知道最优的策略是什么，因此往往从随机的策略开始，使用随机的策略进行试验，就可以得到一系列的状态,动作和反馈